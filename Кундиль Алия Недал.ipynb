{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# emotional coloring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\user\\anaconda3\\lib\\site-packages (22.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "#pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 73 193\n",
      "[('аттракциондордун', 1), ('аракети', 1), ('таптакыр', 1), ('ыңгайлашкан', 1), ('тыкан', 3), ('иштетилген', 1), ('активдүү', 3), ('альтруист', 1), ('периштелик', 2), ('чыныгы', 2)]\n",
      "аттракциондордун аракети таптакыр, ыңгайлашкан, тыкан, тыкан, иштетилген,\n",
      "\n",
      "[[  0   0   0 ...  39  39 201]\n",
      " [  0   0  40 ... 204  40  82]\n",
      " [ 39  80  82 ...  40 205  83]\n",
      " ...\n",
      " [  0   0   0 ... 770 771 772]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ... 773 195 196]]\n",
      "[('боорукер', 1), ('алуу', 2), ('жаман', 3), ('сүйкүмдүү', 4), ('ыраазы', 5), ('дем', 6), ('сүйүү', 7), ('ачык', 8), ('жаркыраган', 9), ('күчтүү', 10), ('ачуу', 11), ('кабыл', 12), ('сонун', 13), ('көз', 14), ('укмуштуу', 15), ('жарык', 16), ('бакыт', 17), ('кубаныч', 18), ('бактылуу', 19), ('ийгилик', 20), ('чынчылдык', 21), ('ишенимдүү', 22), ('жандуу', 23), ('сүйүктүү', 24), ('сыйкырдуу', 25), ('даяр', 26), ('кереметтүү', 27), ('татыктуу', 28), ('чын', 29), ('жүрөктөн', 30), ('катаал', 31), ('эс', 32), ('мыкты', 33), ('аң', 34), ('акылдуу', 35), ('таза', 36), ('кир', 37), ('чириген', 38), ('тыкан', 39), ('активдүү', 40), ('жыпар', 41), ('жыттуу', 42), ('тынч', 43), ('коопсуз', 44), ('чексиз', 45), ('берекелүү', 46), ('пайдалуу', 47), ('шайыр', 48), ('кызыктуу', 49), ('даамдуу', 50), ('берүүчү', 51), ('сулуу', 52), ('ырахат', 53), ('жагымдуу', 54), ('достук', 55), ('жүрөк', 56), ('эстүү', 57), ('билимдүү', 58), ('тапкычтык', 59), ('менен', 60), ('таттуу', 61), ('жаңы', 62), ('асмандагы', 63), ('алгыс', 64), ('эмес', 65), ('оптимисттик', 66), ('алган', 67), ('сезимдүү', 68), ('жөнөкөй', 69), ('гүлдөп', 70), ('чынчыл', 71), ('жылмаюу', 72), ('жакшы', 73), ('жинди', 74), ('кылуу', 75), ('көрө', 76), ('албастык', 77), ('уят', 78), ('кызыксыз', 79), ('периштелик', 80), ('чыныгы', 81), ('периште', 82), ('амбициялуу', 83), ('ыраазычылык', 84), ('байлык', 85), ('кудайлык', 86), ('бай', 87), ('тез', 88), ('рахат', 89), ('көңүл', 90), ('көрүнүктүү', 91), ('кунт', 92), ('коюп', 93), ('гармония', 94), ('боорукердик', 95), ('жетишкендик', 96), ('адептүү', 97), ('кымбат', 98), ('рух', 99), ('жан', 100), ('жашоо', 101), ('күлкүлүү', 102), ('сак', 103), ('ден', 104), ('соолук', 105), ('акыл', 106), ('атактуу', 107), ('кемчиликсиз', 108), ('чыгармачылык', 109), ('салкын', 110), ('баарлашкан', 111), ('жеңилдик', 112), ('макул', 113), ('жеңил', 114), ('кымбаттуу', 115), ('кубанычтуу', 116), ('өзүн', 117), ('кыял', 118), ('заматта', 119), ('тынчтык', 120), ('жаш', 121), ('күч', 122), ('кайраттуу', 123), ('назиктик', 124), ('укмуштуудай', 125), ('өзгөчө', 126), ('кучактап', 127), ('бекитүү', 128), ('жандандыруу', 129), ('акыркы', 130), ('чечкиндүү', 131), ('оригиналдуу', 132), ('эң', 133), ('белек', 134), ('оң', 135), ('берүү', 136), ('жеңүүчү', 137), ('энергиялуу', 138), ('энергия', 139), ('позитивдүү', 140), ('кубаттоо', 141), ('туруктуу', 142), ('туура', 143), ('ылайыктуу', 144), ('бейиш', 145), ('ынталуу', 146), ('романтика', 147), ('люкс', 148), ('эркиндик', 149), ('күн', 150), ('ишенген', 151), ('эркин', 152), ('ыйык', 153), ('жылуу', 154), ('токтоо', 155), ('триумф', 156), ('сабырдуу', 157), ('үрөй', 158), ('f', 159), ('сезимтал', 160), ('эффективдүү', 161), ('тозок', 162), ('келген', 163), ('ырайымсыз', 164), ('алсыз', 165), ('сасык', 166), ('бок', 167), ('капа', 168), ('ач', 169), ('керексиз', 170), ('каар', 171), ('алдоо', 172), ('кан', 173), ('кара', 174), ('кыкырык', 175), ('оор', 176), ('азап', 177), ('өч', 178), ('неприятно', 179), ('чыккынчылык', 180), ('fre', 181), ('k', 182), ('шектүү', 183), ('кыратуучу', 184), ('каардуу', 185), ('жанкечтилик', 186), ('алсыздык', 187), ('сынган', 188), ('тынчсыздануу', 189), ('муздак', 190), ('кызы', 191), ('чуу', 192), ('шок', 193), ('уу', 194), ('бул', 195), ('жакка', 196), ('аттракциондордун', 197), ('аракети', 198), ('таптакыр', 199), ('ыңгайлашкан', 200), ('иштетилген', 201), ('альтруист', 202), ('авторитеттүү', 203), ('спорттук', 204), ('альтруисттик', 205), ('аристократиялык', 206), ('атиптик', 207), ('авторитет', 208), ('аппетиттүү', 209), ('атлетикалык', 210), ('аналитикалык', 211), ('бейпилдик', 212), ('бекер', 213), ('асылдык', 214), ('шайырлык', 215), ('бонус', 216), ('алмаз', 217), ('балансы', 218), ('калыс', 219), ('коркпогон', 220), ('баа', 221), ('жеткис', 222), ('асыл', 223), ('колдоочу', 224), ('жыргал', 225), ('жакындык', 226), ('кудай', 227), ('браво', 228), ('шыктануу', 229), ('ыйман', 230), ('жаз', 231), ('утуш', 232), ('алыш', 233), ('кундор', 234), ('шаардын', 235), ('борбору', 236), ('оо', 237), ('өйдө', 238), ('илхам', 239), ('сылык', 240), ('берешен', 241), ('ишеним', 242), ('ишенүү', 243), ('берилгендик', 244), ('түз', 245), ('чокулар', 246), ('көңүлдүү', 247), ('түбөлүктүүлүк', 248), ('түбөлүктүү', 249), ('толкунданган', 250), ('тарбияланган', 251), ('үстөмдүк', 252), ('эстеп', 253), ('ички', 254), ('улуу', 255), ('кыялдануу', 256), ('тарбиялоо', 257), ('калыбына', 258), ('келтирүү', 259), ('энтузиаздуу', 260), ('суктанган', 261), ('таасирдүү', 262), ('бардыгы', 263), ('бардыгын', 264), ('кечирүүчү', 265), ('тойгузган', 266), ('тандоо', 267), ('тандап', 268), ('кирешелүү', 269), ('аткарылган', 270), ('аткаруу', 271), ('алым', 272), ('тоо', 273), ('сыймык', 274), ('меймандостук', 275), ('гармониялуу', 276), ('гений', 277), ('фитнес', 278), ('текебер', 279), ('баатыр', 280), ('акча', 281), ('балдар', 282), ('жакшылык', 283), ('бакубатчылык', 284), ('достор', 285), ('ооба', 286), ('аракет', 287), ('данди', 288), ('динамикалуу', 289), ('дипломатиялык', 290), ('саламдашуу', 291), ('ак', 292), ('абийирдүү', 293), ('канааттанган', 294), ('абдан', 295), ('узак', 296), ('өмүр', 297), ('ынтымактуу', 298), ('рухий', 299), ('биримдик', 300), ('нике', 301), ('каалоосу', 302), ('каалаган', 303), ('жомоктогудай', 304), ('камкор', 305), ('негиздүү', 306), ('жай', 307), ('сакталган', 308), ('уялчаак', 309), ('корголгон', 310), ('жылдыздуу', 311), ('үндүү', 312), ('дени', 313), ('жашыл', 314), ('тааныш', 315), ('билүүчү', 316), ('мазмундуу', 317), ('оюн', 318), ('ойноок', 319), ('идея', 320), ('молчулук', 321), ('ойлоп', 322), ('табуучулук', 323), ('сымбаттуу', 324), ('инновациячыл', 325), ('инновация', 326), ('инстинктивдүүлүк', 327), ('интеллект', 328), ('интеллектуалдык', 329), ('интуитивдүүлүк', 330), ('интуитивдик', 331), ('бирдик', 332), ('чебер', 333), ('өнөрү', 334), ('айыккан', 335), ('айыктыруу', 336), ('булз', 337), ('каникул', 338), ('карусель', 339), ('комедия', 340), ('фильм', 341), ('момпосуй', 342), ('корпоративдик', 343), ('сулуулук', 344), ('сапаты', 345), ('классикалык', 346), ('көптөшкөн', 347), ('ыңгайлуу', 348), ('чечен', 349), ('сылап', 350), ('жайкы', 351), ('лидер', 352), ('легендарлуу', 353), ('мээримдүү', 354), ('апам', 355), ('массаж', 356), ('бал', 357), ('айы', 358), ('дүйнө', 359), ('деңиз', 360), ('балмуздак', 361), ('сыйкыр', 362), ('чеберчилик', 363), ('келечектүү', 364), ('жүрөгү', 365), ('мотивация', 366), ('акылман', 367), ('сыйлык', 368), ('үмүт', 369), ('ишенимдүүлүк', 370), ('жыл', 371), ('сыйлыктуу', 372), ('намасте', 373), ('табигый', 374), ('жумшак', 375), ('карандысыз', 376), ('жеӊилгис', 377), ('кебелбес', 378), ('тайсалгыс', 379), ('туруштук', 380), ('бере', 381), ('жупуну', 382), ('реалдуу', 383), ('айтылгыс', 384), ('теңдешсиз', 385), ('чыдамсыз', 386), ('туруксуз', 387), ('нирвана', 388), ('нерсе', 389), ('мол', 390), ('үмүттүү', 391), ('сергиткен', 392), ('жаңыланган', 393), ('элестүү', 394), ('кулагы', 395), ('укпаган', 396), ('чоң', 397), ('мааниге', 398), ('ээ', 399), ('бир', 400), ('жандантуу', 401), ('жашартуу', 402), ('сергитүү', 403), ('жарыктанган', 404), ('жеңилдеген', 405), ('алсыраган', 406), ('жоосун', 407), ('сокур', 408), ('курч', 409), ('башкача', 410), ('бааланган', 411), ('жеңиштин', 412), ('жеңүүчүсү', 413), ('өбүү', 414), ('майрамы', 415), ('арноо', 416), ('өсүш', 417), ('айлыкка', 418), ('байге', 419), ('сапары', 420), ('жума', 421), ('эсте', 422), ('каларлык', 423), ('пионер', 424), ('козгоо', 425), ('кыймылдуу', 426), ('аш', 427), ('болумдуу', 428), ('колдоо', 429), ('мүмкүнчүлүк', 430), ('куттуктайбыз', 431), ('жылмаланган', 432), ('терең', 433), ('ойлор', 434), ('түшүнүү', 435), ('популярдуу', 436), ('ардактуу', 437), ('урматтуу', 438), ('адилдик', 439), ('майрам', 440), ('практикалык', 441), ('трансформация', 442), ('берилген', 443), ('азыркы', 444), ('өзгөрүүчү', 445), ('тосуп', 446), ('аракетчил', 447), ('принципиалдуу', 448), ('алынган', 449), ('демилгелүү', 450), ('жарыяланган', 451), ('прогресс', 452), ('жемиштүү', 453), ('агартуу', 454), ('кечиримдүү', 455), ('көбүктүү', 456), ('жалындаган', 457), ('жапжашыл', 458), ('асан', 459), ('үсөн', 460), ('сатуу', 461), ('бала', 462), ('балык', 463), ('уулоо', 464), ('теңдик', 465), ('нурлуу', 466), ('ар', 467), ('тараптуу', 468), ('өнүккөн', 469), ('бийик', 470), ('рухтуу', 471), ('чечүүчү', 472), ('жар', 473), ('өсүү', 474), ('той', 475), ('датасы', 476), ('үй', 477), ('бүлө', 478), ('арзандатуу', 479), ('күлкү', 480), ('курорт', 481), ('сюрприз', 482), ('жонокой', 483), ('журок', 484), ('жылмайган', 485), ('кенен', 486), ('тартиптуу', 487), ('өзү', 488), ('өзүнө', 489), ('салмактуу', 490), ('багынып', 491), ('азыр', 492), ('сенсациялуу', 493), ('момун', 494), ('атак', 495), ('даңктуу', 496), ('тамашакөй', 497), ('күлүү', 498), ('маани', 499), ('кемчиликсиздик', 500), ('болуу', 501), ('мазмун', 502), ('байланыш', 503), ('сезим', 504), ('күнөстүү', 505), ('көңүлүн', 506), ('бурган', 507), ('турган', 508), ('кызматташуу', 509), ('ширелүү', 510), ('жөндөмдүү', 511), ('адилеттүү', 512), ('жамаатчыл', 513), ('тик', 514), ('жалындуу', 515), ('супер', 516), ('маанилүү', 517), ('талант', 518), ('творчество', 519), ('чыгармачыл', 520), ('учурдагы', 521), ('назик', 522), ('чыдамкай', 523), ('аккан', 524), ('жалгыз', 525), ('учурган', 526), ('тийген', 527), ('эмгекчил', 528), ('кылдат', 529), ('кооздук', 530), ('укмуш', 531), ('ынанымдуу', 532), ('сыйлуу', 533), ('озуно', 534), ('жайлуу', 535), ('уруктандыруу', 536), ('канааттандырарлык', 537), ('кайталангыс', 538), ('сергек', 539), ('бекемдик', 540), ('тең', 541), ('салмактуулук', 542), ('бийиктик', 543), ('ийгиликтүү', 544), ('ырастоочу', 545), ('татаал', 546), ('катышат', 547), ('сылыктык', 548), ('rt', 549), ('rtit', 550), ('фейерверк', 551), ('фантастикалык', 552), ('феноменалдык', 553), ('филиграндык', 554), ('философиялык', 555), ('freebie', 556), ('мактоо', 557), ('гүлдөр', 558), ('харизматикалык', 559), ('чың', 560), ('эр', 561), ('цирк', 562), ('гүлү', 563), ('баалуу', 564), ('максаттуу', 565), ('намыс', 566), ('чемпиону', 567), ('жана', 568), ('сезүү', 569), ('керемет', 570), ('шоколад', 571), ('берешендик', 572), ('эйфория', 573), ('экстази', 574), ('попсикл', 575), ('экспансиондуу', 576), ('экстаздуу', 577), ('жарашыктуу', 578), ('электрлештирүүчү', 579), ('эмоционалдуу', 580), ('эмпатия', 581), ('энтузиазм', 582), ('этикалык', 583), ('эфирдик', 584), ('кыйроого', 585), ('учураган', 586), ('учак', 587), ('кырсыгы', 588), ('жоко', 589), ('чыгаруу', 590), ('сырттан', 591), ('апаат', 592), ('банкрот', 593), ('курөш', 594), ('ооруган', 595), ('даамсыз', 596), ('байкуш', 597), ('бородуу', 598), ('de', 599), ('siz', 600), ('y', 601), ('syz', 602), ('бакшы', 603), ('вирус', 604), ('тиш', 605), ('согушу', 606), ('күрөшүү', 607), ('зяндуу', 608), ('odono', 609), ('b', 610), ('rb', 611), ('ri', 612), ('n', 613), ('күнөөлүү', 614), ('күнөлүү', 615), ('айыптоо', 616), ('зянду', 617), ('ачкалык', 618), ('кычыткы', 619), ('орой', 620), ('иплас', 621), ('келесоо', 622), ('келесоолук', 623), ('демейки', 624), ('карыз', 625), ('акмак', 626), ('деформация', 627), ('ланган', 628), ('жапайы', 629), ('жабырлануучу', 630), ('сойку', 631), ('катуу', 632), ('мыкаачылык', 633), ('тыю', 634), ('кирип', 635), ('көгөрүп', 636), ('тыгылып', 637), ('калуу', 638), ('бузулган', 639), ('лагард', 640), ('лайм', 641), ('ишенимге', 642), ('албоо', 643), ('чарчоо', 644), ('кырсык', 645), ('кеме', 646), ('кыйроо', 647), ('уурулук', 648), ('кризис', 649), ('төгүү', 650), ('кредит', 651), ('тикенек', 652), ('кансыраган', 653), ('маньяк', 654), ('микробдор', 655), ('мистицизм', 656), ('скандалдык', 657), ('ун', 658), ('чычкан', 659), ('капкан', 660), ('өлгөн', 661), ('өлүү', 662), ('айплас', 663), ('алуучу', 664), ('жаза', 665), ('зомбулук', 666), ('терс', 667), ('эч', 668), ('кандай', 669), ('коркуп', 670), ('корккон', 671), ('абийирсиз', 672), ('ийгиликсиз', 673), ('утулган', 674), ('каталуу', 675), ('түшүнүксүз', 676), ('наивный', 677), ('тентек', 678), ('ец', 679), ('качан', 680), ('недескрипт', 681), ('баса', 682), ('белгиледи', 683), ('нежелательно', 684), ('неприятное', 685), ('субстандарт', 686), ('таарыныч', 687), ('милдет', 688), ('милдети', 689), ('тоноо', 690), ('жалгыздык', 691), ('отставкага', 692), ('жоктоо', 693), ('тер', 694), ('жийиркеничтүү', 695), ('кемсинтүү', 696), ('акарат', 697), ('жийиркеничт', 698), ('айып', 699), ('жасалма', 700), ('орунтуу', 701), ('полтергеист', 702), ('жоготуу', 703), ('кыноо', 704), ('тымызын', 705), ('талашуу', 706), ('жаралоо', 707), ('өкүнүчтүү', 708), ('жек', 709), ('көргөн', 710), ('пессимист', 711), ('rejudice', 712), ('ky', 713), ('ltyruu', 714), ('бузуу', 715), ('ажырашуу', 716), ('кыйратуучу', 717), ('күнүмдүк', 718), ('кеӊитүү', 719), ('коририяк', 720), ('чачыраган', 721), ('кусуу', 722), ('бузуку', 723), ('тартиби', 724), ('санкция', 725), ('жеригүү', 726), ('жашы', 727), ('өлүм', 728), ('чатак', 729), ('сууктан', 730), ('коркуу', 731), ('сот', 732), ('убаракерчилик', 733), ('слабак', 734), ('карылык', 735), ('стресс', 736), ('эңкейди', 737), ('караңгылык', 738), ('террордук', 739), ('чабуул', 740), ('меланхоли', 741), ('коркоктук', 742), ('таштанды', 743), ('нерселер', 744), ('түрмө', 745), ('оордук', 746), ('теракт', 747), ('мумкунчулук', 748), ('оорчулук', 749), ('кыйынчылыктарга', 750), ('чыдайт', 751), ('киши', 752), ('өлтүрүү', 753), ('зыяан', 754), ('учурарлык', 755), ('коркутуу', 756), ('чиркин', 757), ('чарчап', 758), ('суук', 759), ('кандуу', 760), ('оору', 761), ('чий', 762), ('монстр', 763), ('желмогуз', 764), ('майда', 765), ('ысык', 766), ('чалууга', 767), ('батынба', 768), ('мен', 769), ('жаманды', 770), ('гана', 771), ('тартам', 772), ('кайра', 773)]\n",
      "(193, 10) (193, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 10, 128)           1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 10, 128)           131584    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,461,122\n",
      "Trainable params: 1,461,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "39/39 [==============================] - 6s 37ms/step - loss: 0.6914 - accuracy: 0.5803\n",
      "Epoch 2/50\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.6829 - accuracy: 0.6218\n",
      "Epoch 3/50\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.6723 - accuracy: 0.6218\n",
      "Epoch 4/50\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.6433 - accuracy: 0.6269\n",
      "Epoch 5/50\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.5748 - accuracy: 0.6684\n",
      "Epoch 6/50\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.4840 - accuracy: 0.6477\n",
      "Epoch 7/50\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.4248 - accuracy: 0.7772\n",
      "Epoch 8/50\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.3777 - accuracy: 0.8135\n",
      "Epoch 9/50\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.3467 - accuracy: 0.8342\n",
      "Epoch 10/50\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.3338 - accuracy: 0.8342\n",
      "Epoch 11/50\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.3291 - accuracy: 0.8446\n",
      "Epoch 12/50\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.3077 - accuracy: 0.8290\n",
      "Epoch 13/50\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.3127 - accuracy: 0.8238\n",
      "Epoch 14/50\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.2965 - accuracy: 0.8342\n",
      "Epoch 15/50\n",
      "39/39 [==============================] - 1s 38ms/step - loss: 0.3185 - accuracy: 0.7979\n",
      "Epoch 16/50\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.2916 - accuracy: 0.8083\n",
      "Epoch 17/50\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.2735 - accuracy: 0.8290\n",
      "Epoch 18/50\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.2627 - accuracy: 0.8497\n",
      "Epoch 19/50\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.2731 - accuracy: 0.8238\n",
      "Epoch 20/50\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.2649 - accuracy: 0.8446\n",
      "Epoch 21/50\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.2491 - accuracy: 0.8394\n",
      "Epoch 22/50\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.2672 - accuracy: 0.8290\n",
      "Epoch 23/50\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.2513 - accuracy: 0.8238\n",
      "Epoch 24/50\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.2460 - accuracy: 0.8394\n",
      "Epoch 25/50\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.2415 - accuracy: 0.8394\n",
      "Epoch 26/50\n",
      "39/39 [==============================] - 1s 35ms/step - loss: 0.2368 - accuracy: 0.8549\n",
      "Epoch 27/50\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.2425 - accuracy: 0.8342\n",
      "Epoch 28/50\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.2356 - accuracy: 0.8497\n",
      "Epoch 29/50\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.2537 - accuracy: 0.8238\n",
      "Epoch 30/50\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.2361 - accuracy: 0.8549\n",
      "Epoch 31/50\n",
      "39/39 [==============================] - 1s 37ms/step - loss: 0.2310 - accuracy: 0.8601\n",
      "Epoch 32/50\n",
      "39/39 [==============================] - 2s 40ms/step - loss: 0.2367 - accuracy: 0.8394\n",
      "Epoch 33/50\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.2305 - accuracy: 0.8601\n",
      "Epoch 34/50\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.2292 - accuracy: 0.8549\n",
      "Epoch 35/50\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.2256 - accuracy: 0.8446\n",
      "Epoch 36/50\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.2323 - accuracy: 0.8497\n",
      "Epoch 37/50\n",
      "39/39 [==============================] - 1s 38ms/step - loss: 0.2208 - accuracy: 0.8653\n",
      "Epoch 38/50\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.2338 - accuracy: 0.8394\n",
      "Epoch 39/50\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.2242 - accuracy: 0.8342\n",
      "Epoch 40/50\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.2324 - accuracy: 0.8394\n",
      "Epoch 41/50\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.2263 - accuracy: 0.8187\n",
      "Epoch 42/50\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.2202 - accuracy: 0.8601\n",
      "Epoch 43/50\n",
      "39/39 [==============================] - 1s 38ms/step - loss: 0.2283 - accuracy: 0.8549\n",
      "Epoch 44/50\n",
      "39/39 [==============================] - 1s 38ms/step - loss: 0.2188 - accuracy: 0.8601\n",
      "Epoch 45/50\n",
      "39/39 [==============================] - 1s 38ms/step - loss: 0.2166 - accuracy: 0.8394\n",
      "Epoch 46/50\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.2142 - accuracy: 0.8653\n",
      "Epoch 47/50\n",
      "39/39 [==============================] - 2s 39ms/step - loss: 0.2173 - accuracy: 0.8549\n",
      "Epoch 48/50\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.2147 - accuracy: 0.8601\n",
      "Epoch 49/50\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.2119 - accuracy: 0.8653\n",
      "Epoch 50/50\n",
      "39/39 [==============================] - 1s 36ms/step - loss: 0.2116 - accuracy: 0.8497\n",
      "['күн', 'азыр']\n",
      "['азыр', 'кайра', 'бул', 'жакка']\n",
      "[[0.5735018  0.42649814]]\n",
      "0\n",
      "[[0.0310511 0.9689489]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input, Dropout, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#стемминг\n",
    "class Porter:\n",
    "    PERFECTIVEGROUND = re.compile(u\"((лык|луу|ла|ин|ун|дуу)|((?<=[ая])(в|вши|вшись)))$\")\n",
    "    REFLEXIVE = re.compile(u\"(с[яь])$\")\n",
    "    ADJECTIVE = re.compile(u\"(да|до|де|дө|дан|дон|ден|дөн|ны|ну|ни|нү|нын|нун|нин|нүн)$\")\n",
    "    PARTICIPLE = re.compile(u\"((лар|лер|лор|лөр)|((?<=[ая])(дар|дер|дор|дөр)))$\")\n",
    "    VERB = re.compile(\n",
    "        u\"((тар|тер|тор|төр|га|ге|го|гө|ка|ке|ко|кө|на||не|ило|ыло|ено|ят|ует|уют|ит|ыт|ены|ить|ыть|ишь|ую|ю)|((?<=[ая])(ла|на|ете|йте|ли|й|л|ем|н|ло|но|ет|ют|ны|ть|ешь|нно)))$\")\n",
    "    NOUN = re.compile(\n",
    "        u\"(а|ев|ов|ие|ье|е|иями|ями|ами|еи|ии|и|ией|ей|ой|ий|й|иям|ям|ием|ем|ам|ом|о|у|ах|иях|ях|ы|ь|ию|ью|ю|ия|ья|я)$\")\n",
    "    RVRE = re.compile(u\"^(.*?[аеиоуыэюяө])(.*)$\")\n",
    "    DERIVATIONAL = re.compile(u\".*[^аеиоуыэюяө]+[аеиоуыэюяө]$\")\n",
    "    SUPERLATIVE = re.compile(u\"(ум|быз)$\")\n",
    "    I = re.compile(u\"и$\")\n",
    "    P = re.compile(u\"ь$\")\n",
    "    NN = re.compile(u\"нн$\")\n",
    "\n",
    "    def stem(word):\n",
    "        word = word.lower()\n",
    "        word = word.replace(u'ё', u'е')\n",
    "        m = re.match(Porter.RVRE, word)\n",
    "        if m and m.groups():\n",
    "            pre = m.group(1)\n",
    "            rv = m.group(2)\n",
    "            temp = Porter.PERFECTIVEGROUND.sub('', rv, 1)\n",
    "            if temp == rv:\n",
    "                rv = Porter.REFLEXIVE.sub('', rv, 1)\n",
    "                temp = Porter.ADJECTIVE.sub('', rv, 1)\n",
    "                if temp != rv:\n",
    "                    rv = temp\n",
    "                    rv = Porter.PARTICIPLE.sub('', rv, 1)\n",
    "                else:\n",
    "                    temp = Porter.VERB.sub('', rv, 1)\n",
    "                    if temp == rv:\n",
    "                        rv = Porter.NOUN.sub('', rv, 1)\n",
    "                    else:\n",
    "                        rv = temp\n",
    "            else:\n",
    "                rv = temp\n",
    "\n",
    "            rv = Porter.I.sub('', rv, 1)\n",
    "\n",
    "            if re.match(Porter.DERIVATIONAL, rv):\n",
    "                rv = Porter.DER.sub('', rv, 1)\n",
    "\n",
    "            temp = Porter.P.sub('', rv, 1)\n",
    "            if temp == rv:\n",
    "                rv = Porter.SUPERLATIVE.sub('', rv, 1)\n",
    "                rv = Porter.NN.sub(u'н', rv, 1)\n",
    "            else:\n",
    "                rv = temp\n",
    "            word = pre + rv\n",
    "        return word\n",
    "\n",
    "    stem = staticmethod(stem)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    " #   print(Porter.stem('прибывший'))\n",
    "\n",
    "    with open(Porter.stem('эмоциялар/оң лексика.txt'), 'r', encoding='utf-8') as f:\n",
    "        texts_true = f.readlines()\n",
    "        texts_true[0] = texts_true[0].replace('\\ufeff', '') #убираем первый невидимый символ\n",
    "\n",
    "    with open(Porter.stem('эмоциялар/терс лексика.txt'), 'r', encoding='utf-8') as f:\n",
    "        texts_false = f.readlines()\n",
    "        texts_false[0] = texts_false[0].replace('\\ufeff', '') #убираем первый невидимый символ\n",
    "\n",
    "    texts = texts_true + texts_false\n",
    "    count_true = len(texts_true)\n",
    "    count_false = len(texts_false)\n",
    "    total_lines = count_true + count_false\n",
    "    print(count_true, count_false, total_lines)\n",
    "\n",
    "\n",
    "    maxWordsCount = 10000\n",
    "    tokenizer = Tokenizer(num_words=maxWordsCount, filters='!–\"—#$%&amp;()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r«»', \n",
    "                          lower=True, split=' ', char_level=False)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "\n",
    "    dist = list(tokenizer.word_counts.items())\n",
    "    print(dist[:10])\n",
    "    print(texts[0][:100])\n",
    "\n",
    "\n",
    "    max_text_len = 10\n",
    "    data = tokenizer.texts_to_sequences(texts)\n",
    "    data_pad = pad_sequences(data, maxlen=max_text_len)\n",
    "    print(data_pad)\n",
    "\n",
    "    print( list(tokenizer.word_index.items()) )\n",
    "\n",
    "\n",
    "    X = data_pad\n",
    "    Y = np.array([[1, 0]]*count_true + [[0, 1]]*count_false)\n",
    "    print(X.shape, Y.shape)\n",
    "\n",
    "    indeces = np.random.choice(X.shape[0], size=X.shape[0], replace=False)\n",
    "    X = X[indeces]\n",
    "    Y = Y[indeces]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(maxWordsCount, 128, input_length = max_text_len))\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=Adam(0.0001))\n",
    "\n",
    "    history = model.fit(X, Y, batch_size=5, epochs=50)\n",
    "\n",
    "    reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
    "\n",
    "    def sequence_to_text(list_of_indices):\n",
    "        words = [reverse_word_map.get(letter) for letter in list_of_indices]\n",
    "        return(words)\n",
    "\n",
    "    t = \"Кутман күн, азыр баарын тактап беребиз, катачылык үчүн кечиресиз.\".lower()\n",
    "    data = tokenizer.texts_to_sequences([t])\n",
    "    data_pad = pad_sequences(data, maxlen=max_text_len)\n",
    "    print(sequence_to_text(data[0]))\n",
    "    \n",
    "    f = \"Биз катаны түшүндүк, азыр баарын тактап беребиз, кайра бул жакка чалбагыла \".lower()\n",
    "    data2 = tokenizer.texts_to_sequences([f])\n",
    "    data_pad2 = pad_sequences(data2, maxlen=max_text_len)\n",
    "    print(sequence_to_text(data2[0]))\n",
    "\n",
    "    res = model.predict(data_pad)\n",
    "    print(res, np.argmax(res), sep='\\n')\n",
    "    res2 = model.predict(data_pad2)\n",
    "    print(res2, np.argmax(res2), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\user\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.12.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.4.1)\n",
      "Requirement already satisfied: tokenizers>=0.10.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.10.3)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.19.5)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.11.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers) (3.4.5)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.1.2)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.1.96)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.0.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.62.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (4.1.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (5.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.11.10)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.11.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.12)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.22.0)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.46)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.1)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers) (1.12.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (0.13.2)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision->sentence-transformers) (6.2.0)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.5.18.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.25.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.8)\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\lib\\site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (8.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.4.0\n",
      "  Downloading Keras-2.4.0-py2.py3-none-any.whl (170 kB)\n",
      "     ------------------------------------ 170.2/170.2 kB 787.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: h5py in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras==2.4.0) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras==2.4.0) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras==2.4.0) (1.19.5)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras==2.4.0) (5.1.2)\n",
      "Requirement already satisfied: tensorflow>=2.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras==2.4.0) (2.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.2.0->keras==2.4.0) (2.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.2.0->keras==2.4.0) (2.2.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.11.2)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.37.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.1.2)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.3.3)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.6.3)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.2.0->keras==2.4.0) (3.17.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.12.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.34.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.2.0->keras==2.4.0) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.2.0->keras==2.4.0) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow>=2.2.0->keras==2.4.0) (3.3.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->keras==2.4.0) (1.33.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->keras==2.4.0) (60.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->keras==2.4.0) (2.1.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->keras==2.4.0) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->keras==2.4.0) (2.22.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->keras==2.4.0) (3.3.7)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->keras==2.4.0) (0.4.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->keras==2.4.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->keras==2.4.0) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->keras==2.4.0) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->keras==2.4.0) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->keras==2.4.0) (4.11.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->keras==2.4.0) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->keras==2.4.0) (2022.5.18.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->keras==2.4.0) (1.25.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->keras==2.4.0) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->keras==2.4.0) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->keras==2.4.0) (4.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->keras==2.4.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->keras==2.4.0) (3.1.1)\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.4.3\n",
      "    Uninstalling Keras-2.4.3:\n",
      "      Successfully uninstalled Keras-2.4.3\n",
      "Successfully installed keras-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -cipy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\user\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install keras==2.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "кутман күн, азыр баарын тактап беребиз, катачылык үчүн кечиресиз. биз катаны түшүндүк, азыр баарын тактап беребиз, кайра бул жакка чалбагыла \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "# инициализировать модель и токенизатор:\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "\n",
    "sent = [\n",
    "    t,\n",
    "    f\n",
    "]\n",
    "# инициализировать словарь: сохраняет токенизированные предложения\n",
    "token = {'input_ids': [], 'attention_mask': []}\n",
    "for sentence in sent:\n",
    "    # закодировать каждое предложение, добавить в словарь\n",
    "    new_token = tokenizer.encode_plus(sentence, max_length=128,\n",
    "                                       truncation=True, padding='max_length',\n",
    "                                       return_tensors='pt')\n",
    "    token['input_ids'].append(new_token['input_ids'][0])\n",
    "    token['attention_mask'].append(new_token['attention_mask'][0])\n",
    "# переформатировать список тензоров в один тензор\n",
    "token['input_ids'] = torch.stack(token['input_ids'])\n",
    "token['attention_mask'] = torch.stack(token['attention_mask'])\n",
    "\n",
    "print(t, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сохраняем токенизированные слова в словаре\n",
    "token = {'input_ids': [], 'attention_mask': []}\n",
    "for sentence in sent:\n",
    "    #кодирование каждого предложения и добавление в словарь\n",
    "    new_token = tokenizer.encode_plus(sentence, max_length=128,\n",
    "                                       truncation=True, padding='max_length',\n",
    "                                       return_tensors='pt')\n",
    "    token['input_ids'].append(new_token['input_ids'][0])\n",
    "    token['attention_mask'].append(new_token['attention_mask'][0])\n",
    "#переформатировать список тензоров в один тензор\n",
    "token['input_ids'] = torch.stack(token['input_ids'])\n",
    "token['attention_mask'] = torch.stack(token['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Обработка токена через модель:\n",
    "output = model(**token)\n",
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4910,  0.7268,  1.0223,  ...,  0.2092,  0.5507,  0.7160],\n",
       "         [-0.2803, -0.0674,  0.7514,  ..., -0.2142,  0.6813,  0.7216],\n",
       "         [-0.0546, -0.0302,  0.7379,  ..., -0.0914,  0.3546,  0.4701],\n",
       "         ...,\n",
       "         [-0.1978,  0.5002,  0.7340,  ...,  0.2647,  0.2187,  0.5096],\n",
       "         [-0.2144,  0.2473,  0.5777,  ...,  0.2526,  0.1348,  0.3829],\n",
       "         [-0.1842,  0.2366,  0.5332,  ...,  0.2295,  0.0730,  0.2417]],\n",
       "\n",
       "        [[-0.4984,  0.7275,  0.7603,  ...,  0.2179,  0.6096,  0.6793],\n",
       "         [ 0.5962,  0.4319,  0.5483,  ...,  0.2105,  0.5040,  0.7513],\n",
       "         [-0.7263,  0.2055,  0.6700,  ..., -0.0831,  0.2164,  0.2584],\n",
       "         ...,\n",
       "         [-0.3157,  0.3186,  0.4702,  ...,  0.2373,  0.1046,  0.2513],\n",
       "         [-0.3703,  0.2820,  0.3957,  ...,  0.1724,  0.0480,  0.2230],\n",
       "         [-0.2935,  0.2915,  0.4176,  ...,  0.1854,  0.0485,  0.1092]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Плотные векторные представления текста содержатся в выходном тензоре last_hidden_state\n",
    "embeddings = output.last_hidden_state\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Изменяем размер тензора внимания:\n",
    "att_mask = token['attention_mask']\n",
    "att_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = att_mask.unsqueeze(-1).expand(embeddings.size()).float()\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_embeddings = embeddings * mask\n",
    "mask_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Затем складываем оставшиеся вложения по оси 1:\n",
    "summed = torch.sum(mask_embeddings, 1)\n",
    "summed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Суммируем количество значений, которым необходимо уделить внимание в каждой позиции тензора:\n",
    "summed_mask = torch.clamp(mask.sum(1), min=1e-9)\n",
    "summed_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2863,  0.5399,  0.7446,  ...,  0.1987,  0.4188,  0.2701],\n",
       "        [-0.2908,  0.6681,  0.5334,  ...,  0.1597,  0.3935,  0.1355]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pooled = summed / summed_mask\n",
    "mean_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первое предложение:  кутман күн, азыр баарын тактап беребиз, катачылык үчүн кечиресиз.\n",
      "Второе предложение:  биз катаны түшүндүк, азыр баарын тактап беребиз, кайра бул жакка чалбагыла \n",
      "Эмоциональная окраска: \n",
      "[[0.5735018  0.42649814]]\n",
      "0\n",
      "Эмоциональная окраска: \n",
      "[[0.0310511 0.9689489]]\n",
      "1\n",
      "Процент сходства: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.97516215]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#Рассчитаем косинусное сходство для предложения 0:\n",
    "# преобразовать из тензора PyTorch в массив numpy\n",
    "mean_pooled = mean_pooled.detach().numpy()\n",
    "#калькулятор\n",
    "print(\"Первое предложение: \", t)\n",
    "print(\"Второе предложение: \", f)\n",
    "print(\"Эмоциональная окраска: \", res, np.argmax(res), sep='\\n')\n",
    "print(\"Эмоциональная окраска: \", res2, np.argmax(res2), sep='\\n')\n",
    "\n",
    "print(\"Процент сходства: \")\n",
    "cosine_similarity(\n",
    "    [mean_pooled[0]],\n",
    "    mean_pooled[1:]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14 14 14]\n",
      "[84 84 84]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([1,2,3])\n",
    "a = np.array([[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]])\n",
    "y = a @ x\n",
    "print(y)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([1,2,3])\n",
    "b = np.array([[[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]],\n",
    "     [[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]],\n",
    "     [[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]]])\n",
    "y = x @ b @ x\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[504 504 504]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([1,2,3])\n",
    "c = np.array([[[[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]],\n",
    "     [[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]],\n",
    "     [[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]]],\n",
    "     [[[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]],\n",
    "     [[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]],\n",
    "     [[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]]],\n",
    "     [[[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]],\n",
    "     [[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]],\n",
    "     [[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]]]])\n",
    "y = x @ c @ x @ x\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.6 3.2 4.8]\n",
      " [1.6 3.2 4.8]\n",
      " [1.6 3.2 4.8]]\n"
     ]
    }
   ],
   "source": [
    "#Определяет шаг нелинейно\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([1,2,3])\n",
    "matrix1 = np.array([[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]])\n",
    "pace1 = np.array([[0.1,0.2,0.3],\n",
    "     [0.1,0.2,0.3],\n",
    "     [0.1,0.2,0.3]])\n",
    "\n",
    "print(matrix1 + np.dot(pace1,matrix1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1.6 3.2 4.8]\n",
      "   [1.6 3.2 4.8]\n",
      "   [1.6 3.2 4.8]]\n",
      "\n",
      "  [[1.6 3.2 4.8]\n",
      "   [1.6 3.2 4.8]\n",
      "   [1.6 3.2 4.8]]\n",
      "\n",
      "  [[1.6 3.2 4.8]\n",
      "   [1.6 3.2 4.8]\n",
      "   [1.6 3.2 4.8]]]\n",
      "\n",
      "\n",
      " [[[1.6 3.2 4.8]\n",
      "   [1.6 3.2 4.8]\n",
      "   [1.6 3.2 4.8]]\n",
      "\n",
      "  [[1.6 3.2 4.8]\n",
      "   [1.6 3.2 4.8]\n",
      "   [1.6 3.2 4.8]]\n",
      "\n",
      "  [[1.6 3.2 4.8]\n",
      "   [1.6 3.2 4.8]\n",
      "   [1.6 3.2 4.8]]]\n",
      "\n",
      "\n",
      " [[[1.6 3.2 4.8]\n",
      "   [1.6 3.2 4.8]\n",
      "   [1.6 3.2 4.8]]\n",
      "\n",
      "  [[1.6 3.2 4.8]\n",
      "   [1.6 3.2 4.8]\n",
      "   [1.6 3.2 4.8]]\n",
      "\n",
      "  [[1.6 3.2 4.8]\n",
      "   [1.6 3.2 4.8]\n",
      "   [1.6 3.2 4.8]]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "matrix2 = np.array([[[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]],\n",
    "     [[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]],\n",
    "     [[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]]])\n",
    "\n",
    "pace2 = np.array([[[.1,.2,.3],\n",
    "     [.1,.2,.3],\n",
    "     [.1,.2,.3]],\n",
    "     [[.1,.2,.3],\n",
    "     [.1,.2,.3],\n",
    "     [.1,.2,.3]],\n",
    "     [[.1,.2,.3],\n",
    "     [.1,.2,.3],\n",
    "     [.1,.2,.3]]])\n",
    "\n",
    "print(matrix2 + np.dot(pace2,matrix2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[[[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]]\n",
      "\n",
      "\n",
      "   [[[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]]\n",
      "\n",
      "\n",
      "   [[[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]]\n",
      "\n",
      "\n",
      "   [[[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]]\n",
      "\n",
      "\n",
      "   [[[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]]\n",
      "\n",
      "\n",
      "   [[[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]]\n",
      "\n",
      "\n",
      "   [[[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]]\n",
      "\n",
      "\n",
      "   [[[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]]\n",
      "\n",
      "\n",
      "   [[[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]]\n",
      "\n",
      "\n",
      "   [[[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]]\n",
      "\n",
      "\n",
      "   [[[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]]\n",
      "\n",
      "\n",
      "   [[[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]]\n",
      "\n",
      "\n",
      "   [[[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]]\n",
      "\n",
      "\n",
      "   [[[ 7.  14.  21. ]\n",
      "     [ 7.  14.  21. ]\n",
      "     [ 7.  14.  21. ]]\n",
      "\n",
      "    [[ 7.  14.  21. ]\n",
      "     [ 7.  14.  21. ]\n",
      "     [ 7.  14.  21. ]]\n",
      "\n",
      "    [[ 7.  14.  21. ]\n",
      "     [ 7.  14.  21. ]\n",
      "     [ 7.  14.  21. ]]]\n",
      "\n",
      "\n",
      "   [[[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]]\n",
      "\n",
      "\n",
      "   [[[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]]\n",
      "\n",
      "\n",
      "   [[[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]]]\n",
      "\n",
      "\n",
      "\n",
      "  [[[[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]]\n",
      "\n",
      "\n",
      "   [[[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]]\n",
      "\n",
      "\n",
      "   [[[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]\n",
      "\n",
      "    [[ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]\n",
      "     [ 1.6  3.2  4.8]]]]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "matrix3 = np.array([[[[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]],\n",
    "     [[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]],\n",
    "     [[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]]],\n",
    "     [[[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]],\n",
    "     [[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]],\n",
    "     [[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]]],\n",
    "     [[[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]],\n",
    "     [[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]],\n",
    "     [[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]]]])\n",
    "\n",
    "pace3 = np.array([[[[.1,.2,.3],\n",
    "     [.1,.2,.3],\n",
    "     [.1,.2,.3]],\n",
    "     [[.1,.2,.3],\n",
    "     [.1,.2,.3],\n",
    "     [.1,.2,.3]],\n",
    "     [[.1,.2,.3],\n",
    "     [.1,.2,.3],\n",
    "     [.1,.2,.3]]],\n",
    "     [[[.1,.2,.3],\n",
    "     [.1,.2,.3],\n",
    "     [.1,.2,.3]],\n",
    "     [[.1,.2,.3],\n",
    "     [.1,.2,.3],\n",
    "     [.1,.2,.3]],\n",
    "     [[.1,.2,.3],\n",
    "     [.1,.2,.3],\n",
    "     [.1,.2,.3]]],\n",
    "     [[[.1,.2,.3],\n",
    "     [1,2,3],\n",
    "     [.1,.2,.3]],\n",
    "     [[.1,.2,.3],\n",
    "     [.1,.2,.3],\n",
    "     [.1,.2,.3]],\n",
    "     [[.1,.2,.3],\n",
    "     [.1,.2,.3],\n",
    "     [.1,.2,.3]]]])\n",
    "\n",
    "print(matrix3 + np.dot(pace3,matrix3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22.4 22.4 22.4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([1,2,3])\n",
    "matrix1 = np.array([[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]])\n",
    "pace1 = np.array([[0.1,0.2,0.3],\n",
    "     [0.1,0.2,0.3],\n",
    "     [0.1,0.2,0.3]])\n",
    "\n",
    "y = (matrix1 + np.dot(pace1,matrix1)) @ x\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[134.4 134.4 134.4]\n",
      " [134.4 134.4 134.4]\n",
      " [134.4 134.4 134.4]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([1,2,3])\n",
    "matrix2 = np.array([[[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]],\n",
    "     [[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]],\n",
    "     [[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]]])\n",
    "\n",
    "pace2 = np.array([[[.1,.2,.3],\n",
    "     [.1,.2,.3],\n",
    "     [.1,.2,.3]],\n",
    "     [[.1,.2,.3],\n",
    "     [.1,.2,.3],\n",
    "     [.1,.2,.3]],\n",
    "     [[.1,.2,.3],\n",
    "     [.1,.2,.3],\n",
    "     [.1,.2,.3]]])\n",
    "\n",
    "b = (matrix2 + np.dot(pace2,matrix2))\n",
    "#y = x @ b @ x @ x\n",
    "y = x @ b @ x\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.6 1.2 1.8]\n",
      "   [0.6 1.2 1.8]\n",
      "   [0.6 1.2 1.8]]\n",
      "\n",
      "  [[0.6 1.2 1.8]\n",
      "   [0.6 1.2 1.8]\n",
      "   [0.6 1.2 1.8]]\n",
      "\n",
      "  [[0.6 1.2 1.8]\n",
      "   [0.6 1.2 1.8]\n",
      "   [0.6 1.2 1.8]]]\n",
      "\n",
      "\n",
      " [[[0.6 1.2 1.8]\n",
      "   [0.6 1.2 1.8]\n",
      "   [0.6 1.2 1.8]]\n",
      "\n",
      "  [[0.6 1.2 1.8]\n",
      "   [0.6 1.2 1.8]\n",
      "   [0.6 1.2 1.8]]\n",
      "\n",
      "  [[0.6 1.2 1.8]\n",
      "   [0.6 1.2 1.8]\n",
      "   [0.6 1.2 1.8]]]\n",
      "\n",
      "\n",
      " [[[0.6 1.2 1.8]\n",
      "   [0.6 1.2 1.8]\n",
      "   [0.6 1.2 1.8]]\n",
      "\n",
      "  [[0.6 1.2 1.8]\n",
      "   [0.6 1.2 1.8]\n",
      "   [0.6 1.2 1.8]]\n",
      "\n",
      "  [[0.6 1.2 1.8]\n",
      "   [0.6 1.2 1.8]\n",
      "   [0.6 1.2 1.8]]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#b = (matrix2 + np.dot(pace2,matrix2))\n",
    "\n",
    "x = np.array([1,2,3])\n",
    "matrix2 = np.array([[[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]],\n",
    "     [[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]],\n",
    "     [[1,2,3],\n",
    "     [1,2,3],\n",
    "     [1,2,3]]])\n",
    "\n",
    "pace2 = np.array([[[.1,.2,.3],\n",
    "     [.1,.2,.3],\n",
    "     [.1,.2,.3]],\n",
    "     [[.1,.2,.3],\n",
    "     [.1,.2,.3],\n",
    "     [.1,.2,.3]],\n",
    "     [[.1,.2,.3],\n",
    "     [.1,.2,.3],\n",
    "     [.1,.2,.3]]])\n",
    "\n",
    "b = np.dot(pace2,matrix2)\n",
    "\n",
    "y = b\n",
    "print(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
